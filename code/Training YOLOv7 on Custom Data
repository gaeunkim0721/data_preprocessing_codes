{"cells":[{"cell_type":"markdown","metadata":{"id":"GD9gUQpaBxNa"},"source":["# How to Train YOLOv7 on a Custom Dataset\n","\n","This tutorial is based on the [YOLOv7 repository](https://github.com/WongKinYiu/yolov7) by WongKinYiu. This notebook shows training on **your own custom objects**. Many thanks to WongKinYiu and AlexeyAB for putting this repository together.\n","\n","\n","### **Accompanying Blog Post**\n","\n","We recommend that you follow along in this notebook while reading the blog post on [how to train YOLOv7](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/), concurrently.\n","\n","### **Steps Covered in this Tutorial**\n","\n","To train our detector we take the following steps:\n","\n","* Install YOLOv7 dependencies\n","* Load custom dataset from Roboflow in YOLOv7 format\n","* Run YOLOv7 training\n","* Evaluate YOLOv7 performance\n","* Run YOLOv7 inference on test images\n","* OPTIONAL: Deployment\n","* OPTIONAL: Active Learning\n","\n","\n","### Preparing a Custom Dataset\n","\n","In this tutorial, we will utilize an open source computer vision dataset from one of the 90,000+ available on [Roboflow Universe](https://universe.roboflow.com).\n","\n","If you already have your own images (and, optionally, annotations), you can convert your dataset using [Roboflow](https://roboflow.com), a set of tools developers use to build better computer vision models quickly and accurately. 100k+ developers use roboflow for (automatic) annotation, converting dataset formats (like to YOLOv7), training, deploying, and improving their datasets/models.\n","\n","Follow [the getting started guide here](https://docs.roboflow.com/quick-start) to create and prepare your own custom dataset."]},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["#Install Dependencies\n","\n","_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nD-uPyQ_2jiN","outputId":"9076469f-d535-4639-b651-ba8a7dfd1a93","executionInfo":{"status":"ok","timestamp":1698556452439,"user_tz":-540,"elapsed":8336,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1191, done.\u001b[K\n","remote: Total 1191 (delta 0), reused 0 (delta 0), pack-reused 1191\u001b[K\n","Receiving objects: 100% (1191/1191), 74.23 MiB | 31.13 MiB/s, done.\n","Resolving deltas: 100% (516/516), done.\n","/content/yolov7/yolov7\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n","Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.3)\n","Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.1.0+cu118)\n","Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.16.0+cu118)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.1)\n","Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.14.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.12.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n","Requirement already satisfied: thop in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (0.1.1.post2209072238)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.12.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.1.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.59.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3.post1)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.19.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.39)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.8)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n"]}],"source":["# Download YOLOv7 repository and install requirements\n","!git clone https://github.com/WongKinYiu/yolov7\n","%cd yolov7\n","!pip install -r requirements.txt"]},{"cell_type":"markdown","metadata":{"id":"mtJ24mPlyF-S"},"source":["# Download Correctly Formatted Custom Data\n","\n","Next, we'll download our dataset in the right format. Use the `YOLOv7 PyTorch` export. Note that this model requires YOLO TXT annotations, a custom YAML file, and organized directories. The roboflow export writes this for us and saves it in the correct spot.\n"]},{"cell_type":"markdown","metadata":{"id":"bHfT9gEiBsBd"},"source":["# Begin Custom Training\n","\n","We're ready to start custom training.\n","\n","NOTE: We will only modify one of the YOLOv7 training defaults in our example: `epochs`. We will adjust from 300 to 100 epochs in our example for speed. If you'd like to change other settings, see details in [our accompanying blog post](https://blog.roboflow.com/yolov7-custom-dataset-training-tutorial/)."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUbmy674bhpD","executionInfo":{"status":"ok","timestamp":1698556453186,"user_tz":-540,"elapsed":754,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"}},"outputId":"55230069-c08a-402d-c78e-fdd9d27e7c40"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","--2023-10-29 05:14:12--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt\n","Resolving github.com (github.com)... 140.82.121.4\n","Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231029%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231029T051412Z&X-Amz-Expires=300&X-Amz-Signature=eebc57c96d07d635de835015720d52c73a45d7cac3a00f60f2c1c365c2fd3d92&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-10-29 05:14:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/13e046d1-f7f0-43ab-910b-480613181b1f?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231029%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231029T051412Z&X-Amz-Expires=300&X-Amz-Signature=eebc57c96d07d635de835015720d52c73a45d7cac3a00f60f2c1c365c2fd3d92&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7_training.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75628875 (72M) [application/octet-stream]\n","Saving to: ‘yolov7_training.pt.1’\n","\n","yolov7_training.pt. 100%[===================>]  72.12M   474MB/s    in 0.2s    \n","\n","2023-10-29 05:14:13 (474 MB/s) - ‘yolov7_training.pt.1’ saved [75628875/75628875]\n","\n"]}],"source":["# download COCO starting checkpoint\n","%cd /content/yolov7\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7_training.pt"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"O5xzs_rEqHVD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698556456392,"user_tz":-540,"elapsed":3209,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"}},"outputId":"efccafad-170c-4eb5-c9d8-e13746f6073f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import zipfile\n","import os\n","from IPython.display import display, clear_output  # Import clear_output\n","\n","# Define the path to the ZIP file, the extraction directory, and the log file\n","zip_file_path = '/content/drive/MyDrive/plate/data.zip'\n","extraction_dir = '/content/drive/MyDrive/extraction_directory'\n","log_file_path = '/content/drive/MyDrive/extraction_log.txt'\n","\n","# Unzip the file\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    total_files = len(zip_ref.infolist())\n","    extracted_files = 0\n","\n","    # Load the progress from the log file if it exists\n","    if os.path.exists(log_file_path):\n","        with open(log_file_path, 'r') as log_file:\n","            extracted_files = int(log_file.read())\n","\n","    for i, member in enumerate(zip_ref.infolist(), start=1):  # start enumeration from 1\n","        # Skip files that have already been processed\n","        if i <= extracted_files:\n","            continue\n","\n","        # Get the directory name\n","        current_dir = os.path.dirname(member.filename)\n","\n","        # Check if the current directory is 'test' and skip it\n","        if 'test' in current_dir.split(os.path.sep):\n","            continue\n","\n","        # Construct the absolute path to the file\n","        target_path = os.path.join(extraction_dir, member.filename)\n","\n","        # Check if the file already exists\n","        if not os.path.exists(target_path):\n","            # Extract the file if it doesn't exist\n","            zip_ref.extract(member, extraction_dir)\n","\n","        # Update the log file\n","        with open(log_file_path, 'w') as log_file:\n","            log_file.write(str(i))\n","\n","        # Print the progress for every file\n","        clear_output(wait=True)  # Clear the previous output\n","        progress_message = (f'Processing directory: {current_dir}\\n'\n","                            f'Progress: {i}/{total_files} files processed, {i} files extracted')\n","        display(progress_message)\n","\n","# Print completion message\n","print(f'Extraction completed: {total_files}/{total_files} files extracted')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"VfmsuFABh5cX","outputId":"ebb3fe98-0d7b-4e66-990e-c4bfbbf7d50c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["'Processing directory: train\\nProgress: 46156/92448 files processed, 46156 files extracted'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{}}]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1698556456393,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"},"user_tz":-540},"id":"1iqOPKjr22mL"},"outputs":[],"source":["# run this cell to begin training\n","%cd /content/yolov7\n","!python train_updated.py --batch 16 --epochs 55 --data /content/plates-1/data.yaml --weights 'yolov7_training.pt' --device 0\n"]},{"cell_type":"markdown","metadata":{"id":"0W0MpUaTCJro"},"source":["# Evaluation\n","\n","We can evaluate the performance of our custom training using the provided evalution script.\n","\n","Note we can adjust the below custom arguments. For details, see [the arguments accepted by detect.py](https://github.com/WongKinYiu/yolov7/blob/main/detect.py#L154)."]},{"cell_type":"code","source":[],"metadata":{"id":"TZUrxoE76LgN"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N4cfnLtTCIce","executionInfo":{"status":"aborted","timestamp":1698556456393,"user_tz":-540,"elapsed":8,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"}}},"outputs":[],"source":["# Run evaluation\n","!python detect.py --weights runs/train/exp/weights/best.pt --conf 0.1 --source {dataset.location}/test/images\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1698556456393,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"},"user_tz":-540},"id":"6AGhNOSSHY4_"},"outputs":[],"source":["#display inference on ALL test images\n","\n","import glob\n","from IPython.display import Image, display\n","\n","i = 0\n","limit = 10000 # max images to print\n","for imageName in glob.glob('/content/yolov7/runs/detect/exp/*.jpg'): #assuming JPG\n","    if i < limit:\n","      display(Image(filename=imageName))\n","      print(\"\\n\")\n","    i = i + 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMOfi7eLJCT3","executionInfo":{"status":"aborted","timestamp":1698556456393,"user_tz":-540,"elapsed":8,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"aMumI7a2JDAN"},"source":["# Reparameterize for Inference\n","\n","https://github.com/WongKinYiu/yolov7/blob/main/tools/reparameterization.ipynb"]},{"cell_type":"markdown","metadata":{"id":"4jn4kCtgKiGO"},"source":["# OPTIONAL: Deployment\n","\n","To deploy, you'll need to export your weights and save them to use later."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wWOok8abrCsL","executionInfo":{"status":"aborted","timestamp":1698556456393,"user_tz":-540,"elapsed":8,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"}}},"outputs":[],"source":["# optional, zip to download weights and results locally\n","\n","!zip -r export.zip runs/detect\n","!zip -r export.zip runs/train/exp/weights/best.pt\n","!zip export.zip runs/train/exp/*"]},{"cell_type":"markdown","metadata":{"id":"f41PvE5gKhYw"},"source":["# OPTIONAL: Active Learning Example\n","\n","Once our first training run is complete, we should use our model to help identify which images are most problematic in order to investigate, annotate, and improve our dataset (and, therefore, model).\n","\n","To do that, we can execute code that automatically uploads images back to our hosted dataset if the image is a specific class or below a given confidence threshold.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mcINqQS7Kt3-","executionInfo":{"status":"aborted","timestamp":1698556456393,"user_tz":-540,"elapsed":8,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"}}},"outputs":[],"source":["# # setup access to your workspace\n","# rf = Roboflow(api_key=\"YOUR_API_KEY\")                               # used above to load data\n","# inference_project =  rf.workspace().project(\"YOUR_PROJECT_NAME\")    # used above to load data\n","# model = inference_project.version(1).model\n","\n","# upload_project = rf.workspace().project(\"YOUR_PROJECT_NAME\")\n","\n","# print(\"inference reference point: \", inference_project)\n","# print(\"upload destination: \", upload_project)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEl1NVE3LSD_","executionInfo":{"status":"aborted","timestamp":1698556456393,"user_tz":-540,"elapsed":8,"user":{"displayName":"Gaeun Kim","userId":"06087335246092429715"}}},"outputs":[],"source":["# # example upload: if prediction is below a given confidence threshold, upload it\n","\n","# confidence_interval = [10,70]                                   # [lower_bound_percent, upper_bound_percent]\n","\n","# for prediction in predictions:                                  # predictions list to loop through\n","#   if(prediction['confidence'] * 100 >= confidence_interval[0] and\n","#           prediction['confidence'] * 100 <= confidence_interval[1]):\n","\n","#           # upload on success!\n","#           print(' >> image uploaded!')\n","#           upload_project.upload(image, num_retry_uploads=3)     # upload image in question"]},{"cell_type":"markdown","metadata":{"id":"LVpCFeU-K4gb"},"source":["# Next steps\n","\n","Congratulations, you've trained a custom YOLOv7 model! Next, start thinking about deploying and [building an MLOps pipeline](https://docs.roboflow.com) so your model gets better the more data it sees in the wild."]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1X9A8odmK4k6l26NDviiT6dd6TgR-piOa","timestamp":1698334237571},{"file_id":"1YnbqOinBZV-c9I7fk_UL6acgnnmkXDMM","timestamp":1657587444672},{"file_id":"1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ","timestamp":1656523193068},{"file_id":"https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb","timestamp":1591755516488}],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}